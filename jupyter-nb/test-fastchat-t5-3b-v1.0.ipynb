{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP5Oq1Qxj+oep1rKeSl++NA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oRAE5kW5-JSW","executionInfo":{"status":"ok","timestamp":1696159828969,"user_tz":-480,"elapsed":149455,"user":{"displayName":"DING FENG","userId":"08114039084591127673"}},"outputId":"1084060e-fb4a-4fa7-8f2a-1c92c0abe2ac"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'fastchat-t5-3b-v1.0'...\n","remote: Enumerating objects: 45, done.\u001b[K\n","remote: Counting objects: 100% (45/45), done.\u001b[K\n","remote: Compressing objects: 100% (27/27), done.\u001b[K\n","remote: Total 45 (delta 17), reused 45 (delta 17), pack-reused 0\u001b[K\n","Unpacking objects: 100% (45/45), 8.84 KiB | 905.00 KiB/s, done.\n","Encountered 1 file(s) that may not have been copied correctly on Windows:\n","\tpytorch_model.bin\n","\n","See: `git lfs help smudge` for more details.\n"]}],"source":["!git clone https://huggingface.co/lmsys/fastchat-t5-3b-v1.0\n"]},{"cell_type":"code","source":["!pip3 install \"fschat[model_worker,webui]\"\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BlpiAeFlAUqx","executionInfo":{"status":"ok","timestamp":1696159952309,"user_tz":-480,"elapsed":24991,"user":{"displayName":"DING FENG","userId":"08114039084591127673"}},"outputId":"00d3d9a9-3047-4923-e633-1fc2124df0b2"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting fschat[model_worker,webui]\n","  Downloading fschat-0.2.29-py3-none-any.whl (200 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/200.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m174.1/200.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.7/200.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from fschat[model_worker,webui]) (3.8.5)\n","Collecting fastapi (from fschat[model_worker,webui])\n","  Downloading fastapi-0.103.2-py3-none-any.whl (66 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httpx (from fschat[model_worker,webui])\n","  Downloading httpx-0.25.0-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting markdown2[all] (from fschat[model_worker,webui])\n","  Downloading markdown2-2.4.10-py2.py3-none-any.whl (39 kB)\n","Collecting nh3 (from fschat[model_worker,webui])\n","  Downloading nh3-0.2.14-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fschat[model_worker,webui]) (1.23.5)\n","Requirement already satisfied: prompt-toolkit>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from fschat[model_worker,webui]) (3.0.39)\n","Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from fschat[model_worker,webui]) (1.10.12)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fschat[model_worker,webui]) (2.31.0)\n","Requirement already satisfied: rich>=10.0.0 in /usr/local/lib/python3.10/dist-packages (from fschat[model_worker,webui]) (13.5.2)\n","Collecting shortuuid (from fschat[model_worker,webui])\n","  Downloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\n","Collecting tiktoken (from fschat[model_worker,webui])\n","  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting uvicorn (from fschat[model_worker,webui])\n","  Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting gradio (from fschat[model_worker,webui])\n","  Downloading gradio-3.45.2-py3-none-any.whl (20.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.2/20.2 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting accelerate>=0.21 (from fschat[model_worker,webui])\n","  Downloading accelerate-0.23.0-py3-none-any.whl (258 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting peft (from fschat[model_worker,webui])\n","  Downloading peft-0.5.0-py3-none-any.whl (85 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.6/85.6 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sentencepiece (from fschat[model_worker,webui])\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from fschat[model_worker,webui]) (2.0.1+cu118)\n","Collecting transformers>=4.31.0 (from fschat[model_worker,webui])\n","  Downloading transformers-4.33.3-py3-none-any.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m114.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from fschat[model_worker,webui]) (3.20.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21->fschat[model_worker,webui]) (23.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21->fschat[model_worker,webui]) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21->fschat[model_worker,webui]) (6.0.1)\n","Collecting huggingface-hub (from accelerate>=0.21->fschat[model_worker,webui])\n","  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit>=3.0.0->fschat[model_worker,webui]) (0.2.6)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->fschat[model_worker,webui]) (4.5.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.0.0->fschat[model_worker,webui]) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.0.0->fschat[model_worker,webui]) (2.16.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->fschat[model_worker,webui]) (3.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->fschat[model_worker,webui]) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->fschat[model_worker,webui]) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->fschat[model_worker,webui]) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->fschat[model_worker,webui]) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->fschat[model_worker,webui]) (3.27.4.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->fschat[model_worker,webui]) (16.0.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->fschat[model_worker,webui]) (2023.6.3)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers>=4.31.0->fschat[model_worker,webui])\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m117.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers>=4.31.0->fschat[model_worker,webui])\n","  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->fschat[model_worker,webui]) (4.66.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->fschat[model_worker,webui]) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->fschat[model_worker,webui]) (3.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->fschat[model_worker,webui]) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->fschat[model_worker,webui]) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->fschat[model_worker,webui]) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->fschat[model_worker,webui]) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->fschat[model_worker,webui]) (1.3.1)\n","Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->fschat[model_worker,webui]) (3.7.1)\n","Collecting starlette<0.28.0,>=0.27.0 (from fastapi->fschat[model_worker,webui])\n","  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio->fschat[model_worker,webui])\n","  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n","Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->fschat[model_worker,webui]) (4.2.2)\n","Collecting ffmpy (from gradio->fschat[model_worker,webui])\n","  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting gradio-client==0.5.3 (from gradio->fschat[model_worker,webui])\n","  Downloading gradio_client-0.5.3-py3-none-any.whl (298 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.4/298.4 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio->fschat[model_worker,webui]) (6.0.1)\n","Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->fschat[model_worker,webui]) (2.1.3)\n","Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->fschat[model_worker,webui]) (3.7.1)\n","Collecting orjson~=3.0 (from gradio->fschat[model_worker,webui])\n","  Downloading orjson-3.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio->fschat[model_worker,webui]) (1.5.3)\n","Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio->fschat[model_worker,webui]) (9.4.0)\n","Collecting pydub (from gradio->fschat[model_worker,webui])\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Collecting python-multipart (from gradio->fschat[model_worker,webui])\n","  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting semantic-version~=2.0 (from gradio->fschat[model_worker,webui])\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Collecting websockets<12.0,>=10.0 (from gradio->fschat[model_worker,webui])\n","  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.5.3->gradio->fschat[model_worker,webui]) (2023.6.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fschat[model_worker,webui]) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fschat[model_worker,webui]) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fschat[model_worker,webui]) (2023.7.22)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn->fschat[model_worker,webui]) (8.1.7)\n","Collecting h11>=0.8 (from uvicorn->fschat[model_worker,webui])\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httpcore<0.19.0,>=0.18.0 (from httpx->fschat[model_worker,webui])\n","  Downloading httpcore-0.18.0-py3-none-any.whl (76 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->fschat[model_worker,webui]) (1.3.0)\n","Collecting wavedrom (from markdown2[all]->fschat[model_worker,webui])\n","  Downloading wavedrom-2.0.3.post3.tar.gz (137 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.7/137.7 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->fschat[model_worker,webui]) (0.4)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->fschat[model_worker,webui]) (4.19.0)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->fschat[model_worker,webui]) (0.12.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->fschat[model_worker,webui]) (1.1.3)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.0.0->fschat[model_worker,webui]) (0.1.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->fschat[model_worker,webui]) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->fschat[model_worker,webui]) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->fschat[model_worker,webui]) (4.42.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->fschat[model_worker,webui]) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->fschat[model_worker,webui]) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->fschat[model_worker,webui]) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio->fschat[model_worker,webui]) (2023.3.post1)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->fschat[model_worker,webui]) (1.3.0)\n","Collecting svgwrite (from wavedrom->markdown2[all]->fschat[model_worker,webui])\n","  Downloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from wavedrom->markdown2[all]->fschat[model_worker,webui]) (1.16.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->fschat[model_worker,webui]) (2023.7.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->fschat[model_worker,webui]) (0.30.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->fschat[model_worker,webui]) (0.10.2)\n","Building wheels for collected packages: ffmpy, wavedrom\n","  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=cb26c453df5a86d89dee4b177e18e8b0a678580bd1333b9fad997d199b765112\n","  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n","  Building wheel for wavedrom (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wavedrom: filename=wavedrom-2.0.3.post3-py2.py3-none-any.whl size=30007 sha256=41050fdd77611450ebf26f1391dfa66a8340aecbc37fcdcd3899cb375cf9f2f0\n","  Stored in directory: /root/.cache/pip/wheels/9c/52/8c/38b454b42f712f325e26f633287484c7dc1ad469e1580c5954\n","Successfully built ffmpy wavedrom\n","Installing collected packages: tokenizers, sentencepiece, safetensors, pydub, nh3, ffmpy, websockets, svgwrite, shortuuid, semantic-version, python-multipart, orjson, markdown2, h11, aiofiles, wavedrom, uvicorn, tiktoken, starlette, huggingface-hub, httpcore, transformers, httpx, fastapi, gradio-client, fschat, gradio, accelerate, peft\n","Successfully installed accelerate-0.23.0 aiofiles-23.2.1 fastapi-0.103.2 ffmpy-0.3.1 fschat-0.2.29 gradio-3.45.2 gradio-client-0.5.3 h11-0.14.0 httpcore-0.18.0 httpx-0.25.0 huggingface-hub-0.17.3 markdown2-2.4.10 nh3-0.2.14 orjson-3.9.7 peft-0.5.0 pydub-0.25.1 python-multipart-0.0.6 safetensors-0.3.3 semantic-version-2.10.0 sentencepiece-0.1.99 shortuuid-1.0.11 starlette-0.27.0 svgwrite-1.4.3 tiktoken-0.5.1 tokenizers-0.13.3 transformers-4.33.3 uvicorn-0.23.2 wavedrom-2.0.3.post3 websockets-11.0.3\n"]}]},{"cell_type":"code","source":["# 命令行交互\n","# !python3 -m fastchat.serve.cli --model-path fastchat-t5-3b-v1.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PcrIROvWAzwI","executionInfo":{"status":"ok","timestamp":1696160719666,"user_tz":-480,"elapsed":713418,"user":{"displayName":"DING FENG","userId":"08114039084591127673"}},"outputId":"cd99fcd9-3789-4d89-92d8-19d2814dfa21"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-10-01 11:33:26.414127: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","Human: hello\n","Assistant: Hello! How can I assist you today?\n","Human: Implement a Python function to compute fibonacci numbers.    \n","Assistant: Sure! Here is an implementation of a Python function that computes the Fibonacci sequence using the`math`module:```#...\n","# 1\n","# 2\n","# 3\n","# 4\n","# 5\n","# 6\n","# 7\n","# 8\n","# 9```This function takes two arguments,`1,`, which is an integer representing the first Fibonacci number (1, 1, 2, 3, 5, 7, 8, etc.), and`5,`, which is the final Fibonacci number (inclusive).\n","The`Math`module provides several functions for calculating Fibonacci sequences, including`math.fibonacci()`,`math.fibonacci(1, 2, 3, 4, 5, 6, 7, 8,...)`,`math.fibonacci(3, 5, 6, 9, 10,...)`,`Math.fibonacci(2, 3, 5, 6, 7, 14, 16, 17, 18, 19, 20, 25, 30)`,`Math.fibonacci(4, 5, 6, 6, 8, 9, 12, 15, 21, 22, 23, 24, 25)`,`Math.fibonacci(5, 3, 5, 6, 7, 8, 9, 12, 15, 20, 25, 27)`,`Math.fibonacci(6, 5, 6, 7, 8, 9, 13, 14, 18, 21, 24)`,`Math.fibonacci(9, 4, 5, 6, 5, 4, 7, 16, 20)`,`Math.fibonacci(8, 3, 5, 6, 7, 8, 13, 15, 19, 20)`,`Math.fibonacci(11, 6, 7, 8, 9, 13, 14)`,`Math.fibonacci(12,\n","Human: Edit the following anticle for spelling and grammar mistakes, and list every changes with detail reasons:  unce upon time lived name John who have pet monkey Jackie. one day while walkin down the street he saw his friend Tom coming to him. \"Hey Tom\" said John \"hows it going?\"  Tom replyied \"Not too bad how 'bout yourself?\". as they was talk Jackie sudden jump onto Tom shoulder and started play with his hair. Tom look at John and ask \"Is that yours?\"  John reply \"Yeah, this crazy lil guy follow me everywhere\" just then Jackie grab hold of Tom glasses and try to take thmm off. Tom struggle to keep his balance as he laugh hystericaly.\n","Assistant: Once upon a time, there lived a man named John who had a pet monkey named Jackie. One day while walking down the street, he saw his friend Tom coming to him.\n","\"Hey Tom\" said John, \"How's it going?\"\n","Tom replied, \"Not too bad, how about yourself?\"\n","As they were talking, Jackie suddenly jumped onto Tom's shoulder and started playing with his hair. Tom immediately looked at John and asked, \"Is that yours?\"\n","John replied, \"Yeah, this crazy little guy follows me everywhere.\"\n","Just then, Jackie grabbed hold of Tom's glasses and tried to take them off. Tom struggled to keep his balance and laughed hysterically.\n","Human: List alll changes and the reasons\n","Assistant: Sure, here are the changes to the passage and their reasons:\n","* Corrected a typo in \"Who lives?\":\n","\"Who lives?\" should be \"What lives?\"\n","* Corrected a misspelling in \"Pet monkey\":\n","\"Pet monkey\" should be \"Jackie\"\n","* Corrected a punctuation error in \"How s it going?\":\n","\"How about yourself?\" should be \"How about yourself?\"\n","* Corrected a grammatical error in \"How's it going?\":\n","\"How about yourself?\" should be \"How about yourself?\"\n","* Corrected a grammatical error in \"Is that yours?\":\n","\"Is that yours?\" should be \"Yeah\", not \"How follows me everywhere\".\n","* Corrected a typo in \"Is that yours?\":\n","\"Is that yours\" should be \"Yeah\", not \"How follows me everywhere\".\n","* Corrected a punctuation error in \"Is that his?\":\n","\"Is that his glasses?\" should be \"Is that his glasses?\"\n","* Corrected a grammatical error in \"Tom struggles to keep his balance\":\n","\"Tom struggles to keep his balance as he laughs hysterically\" should be \"Tom struggles to keep his balance as he laughs\"\n","* Corrected a grammatical error in \"There are no other people in the story.\":\n","\"There are only two people in\n","Human: exit...\n"]}]},{"cell_type":"markdown","source":["启用 UI 版本："],"metadata":{"id":"ukMsCgZZEUBD"}},{"cell_type":"code","source":["!nohup /usr/bin/python3 -m fastchat.serve.controller --port=8088 --host=127.0.0.1 &"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hOaPC2SYEOWY","executionInfo":{"status":"ok","timestamp":1696161567508,"user_tz":-480,"elapsed":742,"user":{"displayName":"DING FENG","userId":"08114039084591127673"}},"outputId":"b507b15c-2182-4f0e-9379-8eed6d170c82"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["nohup: appending output to 'nohup.out'\n"]}]},{"cell_type":"code","source":["# !tail -f nohup.out\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5ExNQdLcHFwX","executionInfo":{"status":"ok","timestamp":1696161640289,"user_tz":-480,"elapsed":4689,"user":{"displayName":"DING FENG","userId":"08114039084591127673"}},"outputId":"38b0e290-d059-4eca-e050-02ff1c7f8191"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-10-01 11:59:19 | INFO | controller | args: Namespace(host='127.0.0.1', port=8088, dispatch_method='shortest_queue', ssl=False)\n","2023-10-01 11:59:19 | ERROR | stderr | INFO:     Started server process [8572]\n","2023-10-01 11:59:19 | ERROR | stderr | INFO:     Waiting for application startup.\n","2023-10-01 11:59:19 | ERROR | stderr | INFO:     Application startup complete.\n","2023-10-01 11:59:19 | ERROR | stderr | INFO:     Uvicorn running on http://127.0.0.1:8088 (Press CTRL+C to quit)\n","^C\n"]}]},{"cell_type":"code","source":["!python3 -m fastchat.serve.model_worker --model-path fastchat-t5-3b-v1.0 --host 127.0.0.1 --port 8089 --worker-address 'http://127.0.0.1:8089' --controller-address 'http://127.0.0.1:8088'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rcjebCM2FAVq","executionInfo":{"status":"ok","timestamp":1696162219389,"user_tz":-480,"elapsed":160281,"user":{"displayName":"DING FENG","userId":"08114039084591127673"}},"outputId":"b0a2026d-f649-4531-861f-31f3e47d1169"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-10-01 12:07:34.342955: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2023-10-01 12:07:35 | INFO | model_worker | args: Namespace(host='127.0.0.1', port=8089, worker_address='http://127.0.0.1:8089', controller_address='http://127.0.0.1:8088', model_path='fastchat-t5-3b-v1.0', revision='main', device='cuda', gpus=None, num_gpus=1, max_gpu_memory=None, dtype=None, load_8bit=False, cpu_offloading=False, gptq_ckpt=None, gptq_wbits=16, gptq_groupsize=-1, gptq_act_order=False, awq_ckpt=None, awq_wbits=16, awq_groupsize=-1, model_names=None, conv_template=None, embed_in_truncate=False, limit_worker_concurrency=5, stream_interval=2, no_register=False, seed=None)\n","2023-10-01 12:07:35 | INFO | model_worker | Loading the model ['fastchat-t5-3b-v1.0'] on worker ed25d4a6 ...\n","You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","2023-10-01 12:10:08 | INFO | model_worker | Register to controller\n","2023-10-01 12:10:08 | ERROR | stderr | Traceback (most recent call last):\n","2023-10-01 12:10:08 | ERROR | stderr |   File \"/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\", line 203, in _new_conn\n","2023-10-01 12:10:08 | ERROR | stderr |     sock = connection.create_connection(\n","2023-10-01 12:10:08 | ERROR | stderr |   File \"/usr/local/lib/python3.10/dist-packages/urllib3/util/connection.py\", line 85, in create_connection\n","2023-10-01 12:10:08 | ERROR | stderr |     raise err\n","2023-10-01 12:10:08 | ERROR | stderr |   File \"/usr/local/lib/python3.10/dist-packages/urllib3/util/connection.py\", line 73, in create_connection\n","2023-10-01 12:10:08 | ERROR | stderr |     sock.connect(sa)\n","2023-10-01 12:10:08 | ERROR | stderr | ConnectionRefusedError: [Errno 111] Connection refused\n","2023-10-01 12:10:08 | ERROR | stderr | \n","2023-10-01 12:10:08 | ERROR | stderr | The above exception was the direct cause of the following exception:\n","2023-10-01 12:10:08 | ERROR | stderr | \n","2023-10-01 12:10:08 | ERROR | stderr | Traceback (most recent call last):\n","2023-10-01 12:10:08 | ERROR | stderr |   File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 790, in urlopen\n","2023-10-01 12:10:08 | ERROR | stderr |     response = self._make_request(\n","2023-10-01 12:10:08 | ERROR | stderr |   File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 496, in _make_request\n","2023-10-01 12:10:08 | ERROR | stderr |     conn.request(\n","2023-10-01 12:10:08 | ERROR | stderr |   File \"/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\", line 395, in request\n","2023-10-01 12:10:08 | ERROR | stderr |     self.endheaders()\n","2023-10-01 12:10:08 | ERROR | stderr |   File \"/usr/lib/python3.10/http/client.py\", line 1278, in endheaders\n","2023-10-01 12:10:08 | ERROR | stderr |     self._send_output(message_body, encode_chunked=encode_chunked)\n","2023-10-01 12:10:08 | ERROR | stderr |   File \"/usr/lib/python3.10/http/client.py\", line 1038, in _send_output\n","2023-10-01 12:10:08 | ERROR | stderr |     self.send(msg)\n","2023-10-01 12:10:08 | ERROR | stderr |   File \"/usr/lib/python3.10/http/client.py\", line 976, in send\n","2023-10-01 12:10:08 | ERROR | stderr |     self.connect()\n","2023-10-01 12:10:08 | ERROR | stderr |   File \"/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\", line 243, in connect\n","2023-10-01 12:10:08 | ERROR | stderr |     self.sock = self._new_conn()\n","2023-10-01 12:10:08 | ERROR | stderr |   File \"/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\", line 218, in _new_conn\n","2023-10-01 12:10:08 | ERROR | stderr |     raise NewConnectionError(\n","2023-10-01 12:10:08 | ERROR | stderr | urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7bbec213aa70>: Failed to establish a new connection: [Errno 111] Connection refused\n","2023-10-01 12:10:08 | ERROR | stderr | \n","2023-10-01 12:10:08 | ERROR | stderr | The above exception was the direct cause of the following exception:\n","2023-10-01 12:10:08 | ERROR | stderr | \n","2023-10-01 12:10:08 | ERROR | stderr | Traceback (most recent call last):\n","2023-10-01 12:10:08 | ERROR | stderr |   File \"/usr/local/lib/python3.10/dist-packages/requests/adapters.py\", line 486, in send\n","2023-10-01 12:10:08 | ERROR | stderr |     resp = conn.urlopen(\n","2023-10-01 12:10:08 | ERROR | stderr |   File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 844, in urlopen\n","2023-10-01 12:10:08 | ERROR | stderr |     retries = retries.increment(\n","2023-10-01 12:10:08 | ERROR | stderr |   File \"/usr/local/lib/python3.10/dist-packages/urllib3/util/retry.py\", line 515, in increment\n","2023-10-01 12:10:08 | ERROR | stderr |     raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n","2023-10-01 12:10:08 | ERROR | stderr | urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='127.0.0.1', port=8088): Max retries exceeded with url: /register_worker (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7bbec213aa70>: Failed to establish a new connection: [Errno 111] Connection refused'))\n","2023-10-01 12:10:08 | ERROR | stderr | \n","2023-10-01 12:10:08 | ERROR | stderr | During handling of the above exception, another exception occurred:\n","2023-10-01 12:10:08 | ERROR | stderr | \n","2023-10-01 12:10:08 | ERROR | stderr | Traceback (most recent call last):\n","2023-10-01 12:10:08 | ERROR | stderr |   File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n","2023-10-01 12:10:08 | ERROR | stderr |     return _run_code(code, main_globals, None,\n","2023-10-01 12:10:08 | ERROR | stderr |   File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n","2023-10-01 12:10:08 | ERROR | stderr |     exec(code, run_globals)\n","2023-10-01 12:10:08 | ERROR | stderr |   File \"/usr/local/lib/python3.10/dist-packages/fastchat/serve/model_worker.py\", line 543, in <module>\n","2023-10-01 12:10:08 | ERROR | stderr |     args, worker = create_model_worker()\n","2023-10-01 12:10:08 | ERROR | stderr |   File \"/usr/local/lib/python3.10/dist-packages/fastchat/serve/model_worker.py\", line 518, in create_model_worker\n","2023-10-01 12:10:08 | ERROR | stderr |     worker = ModelWorker(\n","2023-10-01 12:10:08 | ERROR | stderr |   File \"/usr/local/lib/python3.10/dist-packages/fastchat/serve/model_worker.py\", line 242, in __init__\n","2023-10-01 12:10:08 | ERROR | stderr |     self.init_heart_beat()\n","2023-10-01 12:10:08 | ERROR | stderr |   File \"/usr/local/lib/python3.10/dist-packages/fastchat/serve/model_worker.py\", line 101, in init_heart_beat\n","2023-10-01 12:10:08 | ERROR | stderr |     self.register_to_controller()\n","2023-10-01 12:10:08 | ERROR | stderr |   File \"/usr/local/lib/python3.10/dist-packages/fastchat/serve/model_worker.py\", line 118, in register_to_controller\n","2023-10-01 12:10:08 | ERROR | stderr |     r = requests.post(url, json=data)\n","2023-10-01 12:10:08 | ERROR | stderr |   File \"/usr/local/lib/python3.10/dist-packages/requests/api.py\", line 115, in post\n","2023-10-01 12:10:08 | ERROR | stderr |     return request(\"post\", url, data=data, json=json, **kwargs)\n","2023-10-01 12:10:08 | ERROR | stderr |   File \"/usr/local/lib/python3.10/dist-packages/requests/api.py\", line 59, in request\n","2023-10-01 12:10:08 | ERROR | stderr |     return session.request(method=method, url=url, **kwargs)\n","2023-10-01 12:10:08 | ERROR | stderr |   File \"/usr/local/lib/python3.10/dist-packages/requests/sessions.py\", line 589, in request\n","2023-10-01 12:10:08 | ERROR | stderr |     resp = self.send(prep, **send_kwargs)\n","2023-10-01 12:10:08 | ERROR | stderr |   File \"/usr/local/lib/python3.10/dist-packages/requests/sessions.py\", line 703, in send\n","2023-10-01 12:10:08 | ERROR | stderr |     r = adapter.send(request, **kwargs)\n","2023-10-01 12:10:08 | ERROR | stderr |   File \"/usr/local/lib/python3.10/dist-packages/requests/adapters.py\", line 519, in send\n","2023-10-01 12:10:08 | ERROR | stderr |     raise ConnectionError(e, request=request)\n","2023-10-01 12:10:08 | ERROR | stderr | requests.exceptions.ConnectionError: HTTPConnectionPool(host='127.0.0.1', port=8088): Max retries exceeded with url: /register_worker (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7bbec213aa70>: Failed to establish a new connection: [Errno 111] Connection refused'))\n"]}]},{"cell_type":"code","source":["!curl http://127.0.0.1:8088\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LqqnbFxjJhwi","executionInfo":{"status":"ok","timestamp":1696162407313,"user_tz":-480,"elapsed":24,"user":{"displayName":"DING FENG","userId":"08114039084591127673"}},"outputId":"ed149a94-f317-476d-be1c-95db01f03486"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["curl: (7) Failed to connect to 127.0.0.1 port 8088 after 0 ms: Connection refused\n"]}]}]}