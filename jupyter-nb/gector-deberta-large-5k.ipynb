{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1RX611Pem71aiCQWGa1umt3nnlUxg_Irj","authorship_tag":"ABX9TyMe3ILvqOhMDsa38JYmnQz6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!git clone https://huggingface.co/gotutiyan/gector-deberta-large-5k"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ClW2Z10FaqC2","executionInfo":{"status":"ok","timestamp":1696670145669,"user_tz":-480,"elapsed":58121,"user":{"displayName":"DING FENG","userId":"08114039084591127673"}},"outputId":"72ac1b86-3b0f-4381-8e9e-1b70d3e050d9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'gector-deberta-large-5k'...\n","remote: Enumerating objects: 16, done.\u001b[K\n","remote: Total 16 (delta 0), reused 0 (delta 0), pack-reused 16\u001b[K\n","Unpacking objects: 100% (16/16), 1.15 MiB | 8.48 MiB/s, done.\n"]}]},{"cell_type":"code","source":["!git clone https://github.com/gotutiyan/gector.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7PLNNeKqch5J","executionInfo":{"status":"ok","timestamp":1696729744463,"user_tz":-480,"elapsed":1518,"user":{"displayName":"DING FENG","userId":"08114039084591127673"}},"outputId":"056bf228-05f0-4a62-9ff6-66c00442b677"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'gector'...\n","remote: Enumerating objects: 37, done.\u001b[K\n","remote: Counting objects: 100% (37/37), done.\u001b[K\n","remote: Compressing objects: 100% (26/26), done.\u001b[K\n","remote: Total 37 (delta 14), reused 29 (delta 9), pack-reused 0\u001b[K\n","Receiving objects: 100% (37/37), 26.56 KiB | 13.28 MiB/s, done.\n","Resolving deltas: 100% (14/14), done.\n"]}]},{"cell_type":"code","source":["!cd gector; ls; pip install -r requirements.txt; mkdir data; cd data; wget https://github.com/grammarly/gector/raw/master/data/verb-form-vocab.txt\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BXW_pPfZc5R4","executionInfo":{"status":"ok","timestamp":1696670900730,"user_tz":-480,"elapsed":117873,"user":{"displayName":"DING FENG","userId":"08114039084591127673"}},"outputId":"ef1dddee-ad4e-4fa1-d57c-3fc2445b4995"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["gector\t predict.py\t   README.md\t     train.py\n","LICENSE  predict_tweak.py  requirements.txt  upload_to_hub.py\n","Collecting accelerate==0.13.2 (from -r requirements.txt (line 1))\n","  Downloading accelerate-0.13.2-py3-none-any.whl (148 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.8/148.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: certifi==2023.7.22 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (2023.7.22)\n","Collecting charset-normalizer==3.2.0 (from -r requirements.txt (line 3))\n","  Downloading charset_normalizer-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (201 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.8/201.8 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting filelock==3.12.2 (from -r requirements.txt (line 4))\n","  Downloading filelock-3.12.2-py3-none-any.whl (10 kB)\n","Requirement already satisfied: fsspec==2023.6.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (2023.6.0)\n","Collecting huggingface-hub==0.16.4 (from -r requirements.txt (line 6))\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: idna==3.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (3.4)\n","Collecting Levenshtein==0.21.1 (from -r requirements.txt (line 8))\n","  Downloading Levenshtein-0.21.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (172 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.5/172.5 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting numpy==1.24.4 (from -r requirements.txt (line 9))\n","  Downloading numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting packaging==23.1 (from -r requirements.txt (line 10))\n","  Downloading packaging-23.1-py3-none-any.whl (48 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: psutil==5.9.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (5.9.5)\n","Requirement already satisfied: PyYAML==6.0.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (6.0.1)\n","Collecting rapidfuzz==3.2.0 (from -r requirements.txt (line 13))\n","  Downloading rapidfuzz-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting regex==2023.8.8 (from -r requirements.txt (line 14))\n","  Downloading regex-2023.8.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m771.9/771.9 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (2.31.0)\n","Collecting tokenizers==0.13.3 (from -r requirements.txt (line 16))\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch==1.12.1 (from -r requirements.txt (line 17))\n","  Downloading torch-1.12.1-cp310-cp310-manylinux1_x86_64.whl (776.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm==4.66.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (4.66.1)\n","Collecting transformers==4.23.1 (from -r requirements.txt (line 19))\n","  Downloading transformers-4.23.1-py3-none-any.whl (5.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting typing-extensions==4.7.1 (from -r requirements.txt (line 20))\n","  Downloading typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n","Collecting urllib3==2.0.4 (from -r requirements.txt (line 21))\n","  Downloading urllib3-2.0.4-py3-none-any.whl (123 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.9/123.9 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tokenizers, urllib3, typing-extensions, regex, rapidfuzz, packaging, numpy, filelock, charset-normalizer, torch, Levenshtein, huggingface-hub, accelerate, transformers\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 2.0.6\n","    Uninstalling urllib3-2.0.6:\n","      Successfully uninstalled urllib3-2.0.6\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.5.0\n","    Uninstalling typing_extensions-4.5.0:\n","      Successfully uninstalled typing_extensions-4.5.0\n","  Attempting uninstall: regex\n","    Found existing installation: regex 2023.6.3\n","    Uninstalling regex-2023.6.3:\n","      Successfully uninstalled regex-2023.6.3\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 23.2\n","    Uninstalling packaging-23.2:\n","      Successfully uninstalled packaging-23.2\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.23.5\n","    Uninstalling numpy-1.23.5:\n","      Successfully uninstalled numpy-1.23.5\n","  Attempting uninstall: filelock\n","    Found existing installation: filelock 3.12.4\n","    Uninstalling filelock-3.12.4:\n","      Successfully uninstalled filelock-3.12.4\n","  Attempting uninstall: charset-normalizer\n","    Found existing installation: charset-normalizer 3.3.0\n","    Uninstalling charset-normalizer-3.3.0:\n","      Successfully uninstalled charset-normalizer-3.3.0\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.0.1+cu118\n","    Uninstalling torch-2.0.1+cu118:\n","      Successfully uninstalled torch-2.0.1+cu118\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.4 which is incompatible.\n","tensorflow 2.13.0 requires numpy<=1.24.3,>=1.22, but you have numpy 1.24.4 which is incompatible.\n","tensorflow 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.7.1 which is incompatible.\n","torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 1.12.1 which is incompatible.\n","torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.12.1 which is incompatible.\n","torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.12.1 which is incompatible.\n","torchvision 0.15.2+cu118 requires torch==2.0.1, but you have torch 1.12.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed Levenshtein-0.21.1 accelerate-0.13.2 charset-normalizer-3.2.0 filelock-3.12.2 huggingface-hub-0.16.4 numpy-1.24.4 packaging-23.1 rapidfuzz-3.2.0 regex-2023.8.8 tokenizers-0.13.3 torch-1.12.1 transformers-4.23.1 typing-extensions-4.7.1 urllib3-2.0.4\n","--2023-10-07 09:28:09--  https://github.com/grammarly/gector/raw/master/data/verb-form-vocab.txt\n","Resolving github.com (github.com)... 192.30.255.112\n","Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/grammarly/gector/master/data/verb-form-vocab.txt [following]\n","--2023-10-07 09:28:10--  https://raw.githubusercontent.com/grammarly/gector/master/data/verb-form-vocab.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 4390076 (4.2M) [text/plain]\n","Saving to: ‘verb-form-vocab.txt’\n","\n","verb-form-vocab.txt 100%[===================>]   4.19M  --.-KB/s    in 0.06s   \n","\n","2023-10-07 09:28:10 (70.5 MB/s) - ‘verb-form-vocab.txt’ saved [4390076/4390076]\n","\n"]}]},{"cell_type":"code","source":["# %cd gector\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oomVfmuMfLY9","executionInfo":{"status":"ok","timestamp":1696671316554,"user_tz":-480,"elapsed":527,"user":{"displayName":"DING FENG","userId":"08114039084591127673"}},"outputId":"bc29e5dd-07e3-4a0a-cdb8-86636e0c28fd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gector/gector\n"]}]},{"cell_type":"code","source":["#  %cd ..\n","\n","\n","!pwd\n","!python --version\n","import os\n","import sys\n","\n","# sys.path.insert(0, \"/content/gector\")\n","\n","print(sys.path)\n","\n","\n","import mypackage\n","import mypackage.foo\n","\n","# from mypackage.foo import fib\n","\n","# # from gector.modeling import GECToR\n","\n","print(mypackage)\n","# dir(mypackage)\n","# fib(10)\n","\n","\n","import gector\n","print(gector)\n","dir(gector)\n","from gector import vocab\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":459},"id":"lh-StY4Tfhnt","executionInfo":{"status":"error","timestamp":1696733307969,"user_tz":-480,"elapsed":324,"user":{"displayName":"DING FENG","userId":"08114039084591127673"}},"outputId":"853728a6-aa7d-4dc2-b9b2-ebef0e365a11"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","Python 3.10.12\n","['/content/gector', '/content/gector', '/content/gector', '/content/gector', '/content/gector', '/content/gector', '/content/gector', '/content/mytest', '/content', '/content/gector', '/content', '/env/python', '/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/usr/local/lib/python3.10/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.10/dist-packages/IPython/extensions', '/root/.ipython']\n","<module 'mypackage' (<_frozen_importlib_external._NamespaceLoader object at 0x7cef50dfd7e0>)>\n","<module 'gector' (<_frozen_importlib_external._NamespaceLoader object at 0x7cef50dfc760>)>\n"]},{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-37-c6f392c76f1c>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgector\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mImportError\u001b[0m: cannot import name 'vocab' from 'gector' (unknown location)","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["!pwd\n","\n","from transformers import AutoTokenizer\n","import gector\n","print(gector.modeling)\n","from gector.modeling import GECToR\n","from gector.predict import predict, load_verb_dict\n","import torch\n","\n","model_id = 'gotutiyan/gector-deberta-large-5k'\n","model = GECToR.from_pretrained(model_id)\n","if torch.cuda.is_available():\n","    model.cuda()\n","tokenizer = AutoTokenizer.from_pretrained(model_id)\n","encode, decode = load_verb_dict('data/verb-form-vocab.txt')\n","srcs = [\n","    'This is a correct sentence.',\n","    'This are a wrong sentences'\n","]\n","corrected = predict(\n","    model, tokenizer, srcs,\n","    encode, decode,\n","    keep_confidence=0.0,\n","    min_error_prob=0.0,\n","    n_iteration=5,\n","    batch_size=2,\n",")\n","print(corrected)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":266},"id":"Hjd3VRj-b_n2","executionInfo":{"status":"error","timestamp":1696675523550,"user_tz":-480,"elapsed":339,"user":{"displayName":"DING FENG","userId":"08114039084591127673"}},"outputId":"e43a4114-83c5-45ad-ef29-5ee59813f868"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gector-dir/gector\n"]},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-54-a9f196aaaaa3>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGECToR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_verb_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'gector' has no attribute 'modeling'"]}]},{"cell_type":"code","source":[],"metadata":{"id":"2qQC_32neGOG"},"execution_count":null,"outputs":[]}]}