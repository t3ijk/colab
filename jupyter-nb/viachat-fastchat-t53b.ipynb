{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"J1EUus9Gc6Nn"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers==4.34.0\n","  Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.0) (3.12.4)\n","Collecting huggingface-hub\u003c1.0,\u003e=0.16.4 (from transformers==4.34.0)\n","  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.0) (1.23.5)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.0) (23.2)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.0) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.0) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.0) (2.31.0)\n","Collecting tokenizers\u003c0.15,\u003e=0.14 (from transformers==4.34.0)\n","  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors\u003e=0.3.1 (from transformers==4.34.0)\n","  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.34.0) (4.66.1)\n","Requirement already satisfied: fsspec\u003e=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.16.4-\u003etransformers==4.34.0) (2023.6.0)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.16.4-\u003etransformers==4.34.0) (4.5.0)\n","Collecting huggingface-hub\u003c1.0,\u003e=0.16.4 (from transformers==4.34.0)\n","  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers==4.34.0) (3.3.1)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers==4.34.0) (3.4)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers==4.34.0) (2.0.7)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-\u003etransformers==4.34.0) (2023.7.22)\n","Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n","Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.0\n","Collecting sentencepiece==0.1.99\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n","Collecting gradio\n","  Downloading gradio-4.1.1-py3-none-any.whl (15.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiofiles\u003c24.0,\u003e=22.0 (from gradio)\n","  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n","Requirement already satisfied: altair\u003c6.0,\u003e=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n","Collecting fastapi (from gradio)\n","  Downloading fastapi-0.104.1-py3-none-any.whl (92 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ffmpy (from gradio)\n","  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting gradio-client==0.7.0 (from gradio)\n","  Downloading gradio_client-0.7.0-py3-none-any.whl (302 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.7/302.7 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httpx (from gradio)\n","  Downloading httpx-0.25.1-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: huggingface-hub\u003e=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.17.3)\n","Requirement already satisfied: importlib-resources\u003c7.0,\u003e=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.1.0)\n","Requirement already satisfied: jinja2\u003c4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n","Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.3)\n","Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n","Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.23.5)\n","Collecting orjson~=3.0 (from gradio)\n","  Downloading orjson-3.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2)\n","Requirement already satisfied: pandas\u003c3.0,\u003e=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n","Requirement already satisfied: pillow\u003c11.0,\u003e=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n","Collecting pydantic\u003e=2.0 (from gradio)\n","  Downloading pydantic-2.4.2-py3-none-any.whl (395 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.8/395.8 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydub (from gradio)\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Collecting python-multipart (from gradio)\n","  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml\u003c7.0,\u003e=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n","Requirement already satisfied: requests~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.31.0)\n","Collecting semantic-version~=2.0 (from gradio)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Collecting tomlkit==0.12.0 (from gradio)\n","  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n","Requirement already satisfied: typer[all]\u003c1.0,\u003e=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.9.0)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.5.0)\n","Collecting uvicorn\u003e=0.14.0 (from gradio)\n","  Downloading uvicorn-0.24.0-py3-none-any.whl (59 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting websockets\u003c12.0,\u003e=10.0 (from gradio)\n","  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.7.0-\u003egradio) (2023.6.0)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair\u003c6.0,\u003e=4.2.0-\u003egradio) (0.4)\n","Requirement already satisfied: jsonschema\u003e=3.0 in /usr/local/lib/python3.10/dist-packages (from altair\u003c6.0,\u003e=4.2.0-\u003egradio) (4.19.1)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair\u003c6.0,\u003e=4.2.0-\u003egradio) (0.12.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003e=0.14.0-\u003egradio) (3.12.4)\n","Requirement already satisfied: tqdm\u003e=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003e=0.14.0-\u003egradio) (4.66.1)\n","Requirement already satisfied: contourpy\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0-\u003egradio) (1.1.1)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0-\u003egradio) (0.12.1)\n","Requirement already satisfied: fonttools\u003e=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0-\u003egradio) (4.43.1)\n","Requirement already satisfied: kiwisolver\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0-\u003egradio) (1.4.5)\n","Requirement already satisfied: pyparsing\u003e=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0-\u003egradio) (3.1.1)\n","Requirement already satisfied: python-dateutil\u003e=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0-\u003egradio) (2.8.2)\n","Requirement already satisfied: pytz\u003e=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas\u003c3.0,\u003e=1.0-\u003egradio) (2023.3.post1)\n","Collecting annotated-types\u003e=0.4.0 (from pydantic\u003e=2.0-\u003egradio)\n","  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n","Collecting pydantic-core==2.10.1 (from pydantic\u003e=2.0-\u003egradio)\n","  Downloading pydantic_core-2.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting typing-extensions~=4.0 (from gradio)\n","  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0-\u003egradio) (3.3.1)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0-\u003egradio) (3.4)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0-\u003egradio) (2.0.7)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0-\u003egradio) (2023.7.22)\n","Requirement already satisfied: click\u003c9.0.0,\u003e=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]\u003c1.0,\u003e=0.9-\u003egradio) (8.1.7)\n","Collecting colorama\u003c0.5.0,\u003e=0.4.3 (from typer[all]\u003c1.0,\u003e=0.9-\u003egradio)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Collecting shellingham\u003c2.0.0,\u003e=1.3.0 (from typer[all]\u003c1.0,\u003e=0.9-\u003egradio)\n","  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n","Requirement already satisfied: rich\u003c14.0.0,\u003e=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]\u003c1.0,\u003e=0.9-\u003egradio) (13.6.0)\n","Collecting h11\u003e=0.8 (from uvicorn\u003e=0.14.0-\u003egradio)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: anyio\u003c4.0.0,\u003e=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi-\u003egradio) (3.7.1)\n","Collecting starlette\u003c0.28.0,\u003e=0.27.0 (from fastapi-\u003egradio)\n","  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httpcore (from httpx-\u003egradio)\n","  Downloading httpcore-1.0.1-py3-none-any.whl (76 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx-\u003egradio) (1.3.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio\u003c4.0.0,\u003e=3.7.1-\u003efastapi-\u003egradio) (1.1.3)\n","Requirement already satisfied: attrs\u003e=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema\u003e=3.0-\u003ealtair\u003c6.0,\u003e=4.2.0-\u003egradio) (23.1.0)\n","Requirement already satisfied: jsonschema-specifications\u003e=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema\u003e=3.0-\u003ealtair\u003c6.0,\u003e=4.2.0-\u003egradio) (2023.7.1)\n","Requirement already satisfied: referencing\u003e=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema\u003e=3.0-\u003ealtair\u003c6.0,\u003e=4.2.0-\u003egradio) (0.30.2)\n","Requirement already satisfied: rpds-py\u003e=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema\u003e=3.0-\u003ealtair\u003c6.0,\u003e=4.2.0-\u003egradio) (0.10.6)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil\u003e=2.7-\u003ematplotlib~=3.0-\u003egradio) (1.16.0)\n","Requirement already satisfied: markdown-it-py\u003e=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich\u003c14.0.0,\u003e=10.11.0-\u003etyper[all]\u003c1.0,\u003e=0.9-\u003egradio) (3.0.0)\n","Requirement already satisfied: pygments\u003c3.0.0,\u003e=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich\u003c14.0.0,\u003e=10.11.0-\u003etyper[all]\u003c1.0,\u003e=0.9-\u003egradio) (2.16.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py\u003e=2.2.0-\u003erich\u003c14.0.0,\u003e=10.11.0-\u003etyper[all]\u003c1.0,\u003e=0.9-\u003egradio) (0.1.2)\n","Building wheels for collected packages: ffmpy\n","  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=99d1edd0776ce6bcbd343dfe9370f138ea3f8ad087705d229a493babc046729f\n","  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n","Successfully built ffmpy\n","Installing collected packages: pydub, ffmpy, websockets, typing-extensions, tomlkit, shellingham, semantic-version, python-multipart, orjson, h11, colorama, annotated-types, aiofiles, uvicorn, starlette, pydantic-core, httpcore, pydantic, httpx, gradio-client, fastapi, gradio\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.5.0\n","    Uninstalling typing_extensions-4.5.0:\n","      Successfully uninstalled typing_extensions-4.5.0\n","  Attempting uninstall: pydantic\n","    Found existing installation: pydantic 1.10.13\n","    Uninstalling pydantic-1.10.13:\n","      Successfully uninstalled pydantic-1.10.13\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lida 0.0.10 requires kaleido, which is not installed.\n","llmx 0.0.15a0 requires cohere, which is not installed.\n","llmx 0.0.15a0 requires openai, which is not installed.\n","llmx 0.0.15a0 requires tiktoken, which is not installed.\n","tensorflow-probability 0.22.0 requires typing-extensions\u003c4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed aiofiles-23.2.1 annotated-types-0.6.0 colorama-0.4.6 fastapi-0.104.1 ffmpy-0.3.1 gradio-4.1.1 gradio-client-0.7.0 h11-0.14.0 httpcore-1.0.1 httpx-0.25.1 orjson-3.9.10 pydantic-2.4.2 pydantic-core-2.10.1 pydub-0.25.1 python-multipart-0.0.6 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.27.0 tomlkit-0.12.0 typing-extensions-4.8.0 uvicorn-0.24.0 websockets-11.0.3\n"]}],"source":["!pip install transformers==4.34.0\n","!pip install sentencepiece==0.1.99\n","!pip install gradio"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"S21mShdFboN1"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"681032af40f0478c9945026fb3dde607","version_major":2,"version_minor":0},"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/2.40k [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"364bdbbad4c54398b2b0c3c38df79d98","version_major":2,"version_minor":0},"text/plain":["Downloading spiece.model:   0%|          | 0.00/792k [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d9eb503ce6694323ad2815f059b1f3d5","version_major":2,"version_minor":0},"text/plain":["Downloading (…)in/added_tokens.json:   0%|          | 0.00/150 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b8e2058a1b7748728393aef8ce6a5ac4","version_major":2,"version_minor":0},"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["You are using the default legacy behaviour of the \u003cclass 'transformers.models.t5.tokenization_t5.T5Tokenizer'\u003e. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3872f9437b3344fbaad50808868aad18","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/1.52k [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"04a6b5180f5b46d19d5d0c4872629ecd","version_major":2,"version_minor":0},"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/6.71G [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6079b870a6af4f0ba16d558c070779c1","version_major":2,"version_minor":0},"text/plain":["Downloading (…)neration_config.json:   0%|          | 0.00/142 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["input_text Translate from english to german: How old are you\n","input_ids tensor([[30355,    15, 32103,    45, 32103, 22269, 32103,    12, 32103, 13692,\n","            10, 32103,   571, 32103,   625, 32103,    33, 32103,    25,     1]])\n","outputs tensor([[    0,  2739, 32106,  4445, 32106,   436, 32106,   292,    58, 32103,\n","             1]])\n","outputs text: \u003cpad\u003e Wie  alt  sind  Sie?\n","\n"]}],"source":["import gradio as gr\n","import torch\n","import gc\n","\n","# Load model directly\n","from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n","\n","\n","device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"lmsys/fastchat-t5-3b-v1.0\")\n","model = AutoModelForSeq2SeqLM.from_pretrained(\"lmsys/fastchat-t5-3b-v1.0\")\n","model = model.to(device)\n","\n","input_text = 'Translate from english to german: How old are you'\n","input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n","print('input_text', input_text)\n","print('input_ids', input_ids)\n","outputs = model.generate(input_ids, max_length=500)\n","print('outputs', outputs)\n","text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","print(\"outputs text:\", text)\n","\n","def greet0(human_inputs):\n","\n","    system_message = \"A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions.\"\n","\n","    input_text = f\"{system_message}\\n### Human: {human_inputs}\\n### Assistant: \"\n","    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n","    print('input_text', input_text)\n","    print('input_ids', input_ids)\n","    outputs = model.generate(input_ids, max_length=500)\n","    print('outputs', outputs)\n","    text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    print(\"outputs text:\", text)\n","    return text\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XQceqUafo6gv"},"outputs":[],"source":["yield_tokens = []\n","def greet_stream(human_inputs):\n","    system_message = \"A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions.\"\n","    input_text = f\"{system_message}\\n### Human: {human_inputs}\\n### Assistant: \"\n","    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n","\n","    max_length = 200\n","    encoder_output = model.encoder(\n","        input_ids=input_ids\n","    )['last_hidden_state']  # (1, len, d_model)\n","\n","    gen_ids = torch.tensor([[0]]).to(device)\n","    past_key_values = None\n","    yield_tokens = []\n","    for i in range(max_length):\n","        out = model.decoder(\n","            input_ids=gen_ids,\n","            encoder_hidden_states=encoder_output,\n","            use_cache=True,\n","            past_key_values=past_key_values,\n","        )\n","        # print(out.past_key_values)\n","        past_key_values = out.past_key_values\n","        last_hidden_state = out.last_hidden_state  # (1, 1, d_model)\n","        lm_logits = model.lm_head(last_hidden_state)  # (1, 1, len_dict)\n","        values, indices = lm_logits[0].topk(2)\n","        # print(tokenizer.convert_ids_to_tokens(indices[0]))\n","        gen_ids = torch.index_select(indices, 1, torch.tensor([0]).to(device))\n","        yield_tokens.append(tokenizer.decode(\n","            gen_ids[0].cpu(), skip_special_tokens=True))\n","        # print(gen_ids[0])\n","        if torch.equal(gen_ids[0], torch.tensor([1])):\n","          # eos token\n","          break\n","        gc.collect()\n","        torch.cuda.empty_cache()\n","        yield \"\".join(yield_tokens)\n","\n","    # stream\n","    return \"\".join(yield_tokens)\n","\n","iface = gr.Interface(fn=greet_stream, inputs=[gr.Textbox(\n","    label=\"Text 1\",\n","    info=\"Initial text\",\n","    lines=3,\n","    value=\"Who are you?\",\n",")], outputs=\"text\")\n","\n","iface.queue()\n","iface.launch(debug=True)\n","\n","\n","# for value in greet_stream('who are you'):\n","#   print(value)\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPu1zuID2YgY8GTxIAizxQ0","machine_shape":"hm","name":"","provenance":[{"file_id":"1kp80WqjO8dPIcVCqtehz59vjEVvSnvye","timestamp":1699249377246},{"file_id":"17oUvBMCTb5dueEhySAZcS8aKJpG4-wnU","timestamp":1699238493613}],"version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}