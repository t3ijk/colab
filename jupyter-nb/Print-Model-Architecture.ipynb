{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNgD76+liFwR4IWK6yTzbNf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vFKQcPEP6dKx","executionInfo":{"status":"ok","timestamp":1702365991192,"user_tz":-480,"elapsed":14418,"user":{"displayName":"DING FENG","userId":"08114039084591127673"}},"outputId":"37a49cfa-fa19-4d65-9ce4-3ec09a6dc5f2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n"]}],"source":["!pip install transformers\n","!pip install sentencepiece\n"]},{"cell_type":"code","source":["from transformers import BertTokenizer, BertForMaskedLM\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ujxpy7i062zS","executionInfo":{"status":"ok","timestamp":1702366416364,"user_tz":-480,"elapsed":2496,"user":{"displayName":"DING FENG","userId":"08114039084591127673"}},"outputId":"b4676c0a-647e-4858-dbf1-519ed399d28f"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":["print(model)\n","\n","param_dict = {pn: p for pn, p in model.named_parameters()}\n","# param_dict = {pn: p for pn, p in param_dict.items() if p.requires_grad}\n","\n","for pn, p in param_dict.items():\n","  print(pn, p.size())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"75_3ZOem7I9M","executionInfo":{"status":"ok","timestamp":1702366420914,"user_tz":-480,"elapsed":418,"user":{"displayName":"DING FENG","userId":"08114039084591127673"}},"outputId":"1614ac2f-b0ed-40b2-c87b-ed661fa596b3"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["BertForMaskedLM(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (cls): BertOnlyMLMHead(\n","    (predictions): BertLMPredictionHead(\n","      (transform): BertPredictionHeadTransform(\n","        (dense): Linear(in_features=768, out_features=768, bias=True)\n","        (transform_act_fn): GELUActivation()\n","        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      )\n","      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n","    )\n","  )\n",")\n","bert.embeddings.word_embeddings.weight torch.Size([30522, 768])\n","bert.embeddings.position_embeddings.weight torch.Size([512, 768])\n","bert.embeddings.token_type_embeddings.weight torch.Size([2, 768])\n","bert.embeddings.LayerNorm.weight torch.Size([768])\n","bert.embeddings.LayerNorm.bias torch.Size([768])\n","bert.encoder.layer.0.attention.self.query.weight torch.Size([768, 768])\n","bert.encoder.layer.0.attention.self.query.bias torch.Size([768])\n","bert.encoder.layer.0.attention.self.key.weight torch.Size([768, 768])\n","bert.encoder.layer.0.attention.self.key.bias torch.Size([768])\n","bert.encoder.layer.0.attention.self.value.weight torch.Size([768, 768])\n","bert.encoder.layer.0.attention.self.value.bias torch.Size([768])\n","bert.encoder.layer.0.attention.output.dense.weight torch.Size([768, 768])\n","bert.encoder.layer.0.attention.output.dense.bias torch.Size([768])\n","bert.encoder.layer.0.attention.output.LayerNorm.weight torch.Size([768])\n","bert.encoder.layer.0.attention.output.LayerNorm.bias torch.Size([768])\n","bert.encoder.layer.0.intermediate.dense.weight torch.Size([3072, 768])\n","bert.encoder.layer.0.intermediate.dense.bias torch.Size([3072])\n","bert.encoder.layer.0.output.dense.weight torch.Size([768, 3072])\n","bert.encoder.layer.0.output.dense.bias torch.Size([768])\n","bert.encoder.layer.0.output.LayerNorm.weight torch.Size([768])\n","bert.encoder.layer.0.output.LayerNorm.bias torch.Size([768])\n","bert.encoder.layer.1.attention.self.query.weight torch.Size([768, 768])\n","bert.encoder.layer.1.attention.self.query.bias torch.Size([768])\n","bert.encoder.layer.1.attention.self.key.weight torch.Size([768, 768])\n","bert.encoder.layer.1.attention.self.key.bias torch.Size([768])\n","bert.encoder.layer.1.attention.self.value.weight torch.Size([768, 768])\n","bert.encoder.layer.1.attention.self.value.bias torch.Size([768])\n","bert.encoder.layer.1.attention.output.dense.weight torch.Size([768, 768])\n","bert.encoder.layer.1.attention.output.dense.bias torch.Size([768])\n","bert.encoder.layer.1.attention.output.LayerNorm.weight torch.Size([768])\n","bert.encoder.layer.1.attention.output.LayerNorm.bias torch.Size([768])\n","bert.encoder.layer.1.intermediate.dense.weight torch.Size([3072, 768])\n","bert.encoder.layer.1.intermediate.dense.bias torch.Size([3072])\n","bert.encoder.layer.1.output.dense.weight torch.Size([768, 3072])\n","bert.encoder.layer.1.output.dense.bias torch.Size([768])\n","bert.encoder.layer.1.output.LayerNorm.weight torch.Size([768])\n","bert.encoder.layer.1.output.LayerNorm.bias torch.Size([768])\n","bert.encoder.layer.2.attention.self.query.weight torch.Size([768, 768])\n","bert.encoder.layer.2.attention.self.query.bias torch.Size([768])\n","bert.encoder.layer.2.attention.self.key.weight torch.Size([768, 768])\n","bert.encoder.layer.2.attention.self.key.bias torch.Size([768])\n","bert.encoder.layer.2.attention.self.value.weight torch.Size([768, 768])\n","bert.encoder.layer.2.attention.self.value.bias torch.Size([768])\n","bert.encoder.layer.2.attention.output.dense.weight torch.Size([768, 768])\n","bert.encoder.layer.2.attention.output.dense.bias torch.Size([768])\n","bert.encoder.layer.2.attention.output.LayerNorm.weight torch.Size([768])\n","bert.encoder.layer.2.attention.output.LayerNorm.bias torch.Size([768])\n","bert.encoder.layer.2.intermediate.dense.weight torch.Size([3072, 768])\n","bert.encoder.layer.2.intermediate.dense.bias torch.Size([3072])\n","bert.encoder.layer.2.output.dense.weight torch.Size([768, 3072])\n","bert.encoder.layer.2.output.dense.bias torch.Size([768])\n","bert.encoder.layer.2.output.LayerNorm.weight torch.Size([768])\n","bert.encoder.layer.2.output.LayerNorm.bias torch.Size([768])\n","bert.encoder.layer.3.attention.self.query.weight torch.Size([768, 768])\n","bert.encoder.layer.3.attention.self.query.bias torch.Size([768])\n","bert.encoder.layer.3.attention.self.key.weight torch.Size([768, 768])\n","bert.encoder.layer.3.attention.self.key.bias torch.Size([768])\n","bert.encoder.layer.3.attention.self.value.weight torch.Size([768, 768])\n","bert.encoder.layer.3.attention.self.value.bias torch.Size([768])\n","bert.encoder.layer.3.attention.output.dense.weight torch.Size([768, 768])\n","bert.encoder.layer.3.attention.output.dense.bias torch.Size([768])\n","bert.encoder.layer.3.attention.output.LayerNorm.weight torch.Size([768])\n","bert.encoder.layer.3.attention.output.LayerNorm.bias torch.Size([768])\n","bert.encoder.layer.3.intermediate.dense.weight torch.Size([3072, 768])\n","bert.encoder.layer.3.intermediate.dense.bias torch.Size([3072])\n","bert.encoder.layer.3.output.dense.weight torch.Size([768, 3072])\n","bert.encoder.layer.3.output.dense.bias torch.Size([768])\n","bert.encoder.layer.3.output.LayerNorm.weight torch.Size([768])\n","bert.encoder.layer.3.output.LayerNorm.bias torch.Size([768])\n","bert.encoder.layer.4.attention.self.query.weight torch.Size([768, 768])\n","bert.encoder.layer.4.attention.self.query.bias torch.Size([768])\n","bert.encoder.layer.4.attention.self.key.weight torch.Size([768, 768])\n","bert.encoder.layer.4.attention.self.key.bias torch.Size([768])\n","bert.encoder.layer.4.attention.self.value.weight torch.Size([768, 768])\n","bert.encoder.layer.4.attention.self.value.bias torch.Size([768])\n","bert.encoder.layer.4.attention.output.dense.weight torch.Size([768, 768])\n","bert.encoder.layer.4.attention.output.dense.bias torch.Size([768])\n","bert.encoder.layer.4.attention.output.LayerNorm.weight torch.Size([768])\n","bert.encoder.layer.4.attention.output.LayerNorm.bias torch.Size([768])\n","bert.encoder.layer.4.intermediate.dense.weight torch.Size([3072, 768])\n","bert.encoder.layer.4.intermediate.dense.bias torch.Size([3072])\n","bert.encoder.layer.4.output.dense.weight torch.Size([768, 3072])\n","bert.encoder.layer.4.output.dense.bias torch.Size([768])\n","bert.encoder.layer.4.output.LayerNorm.weight torch.Size([768])\n","bert.encoder.layer.4.output.LayerNorm.bias torch.Size([768])\n","bert.encoder.layer.5.attention.self.query.weight torch.Size([768, 768])\n","bert.encoder.layer.5.attention.self.query.bias torch.Size([768])\n","bert.encoder.layer.5.attention.self.key.weight torch.Size([768, 768])\n","bert.encoder.layer.5.attention.self.key.bias torch.Size([768])\n","bert.encoder.layer.5.attention.self.value.weight torch.Size([768, 768])\n","bert.encoder.layer.5.attention.self.value.bias torch.Size([768])\n","bert.encoder.layer.5.attention.output.dense.weight torch.Size([768, 768])\n","bert.encoder.layer.5.attention.output.dense.bias torch.Size([768])\n","bert.encoder.layer.5.attention.output.LayerNorm.weight torch.Size([768])\n","bert.encoder.layer.5.attention.output.LayerNorm.bias torch.Size([768])\n","bert.encoder.layer.5.intermediate.dense.weight torch.Size([3072, 768])\n","bert.encoder.layer.5.intermediate.dense.bias torch.Size([3072])\n","bert.encoder.layer.5.output.dense.weight torch.Size([768, 3072])\n","bert.encoder.layer.5.output.dense.bias torch.Size([768])\n","bert.encoder.layer.5.output.LayerNorm.weight torch.Size([768])\n","bert.encoder.layer.5.output.LayerNorm.bias torch.Size([768])\n","bert.encoder.layer.6.attention.self.query.weight torch.Size([768, 768])\n","bert.encoder.layer.6.attention.self.query.bias torch.Size([768])\n","bert.encoder.layer.6.attention.self.key.weight torch.Size([768, 768])\n","bert.encoder.layer.6.attention.self.key.bias torch.Size([768])\n","bert.encoder.layer.6.attention.self.value.weight torch.Size([768, 768])\n","bert.encoder.layer.6.attention.self.value.bias torch.Size([768])\n","bert.encoder.layer.6.attention.output.dense.weight torch.Size([768, 768])\n","bert.encoder.layer.6.attention.output.dense.bias torch.Size([768])\n","bert.encoder.layer.6.attention.output.LayerNorm.weight torch.Size([768])\n","bert.encoder.layer.6.attention.output.LayerNorm.bias torch.Size([768])\n","bert.encoder.layer.6.intermediate.dense.weight torch.Size([3072, 768])\n","bert.encoder.layer.6.intermediate.dense.bias torch.Size([3072])\n","bert.encoder.layer.6.output.dense.weight torch.Size([768, 3072])\n","bert.encoder.layer.6.output.dense.bias torch.Size([768])\n","bert.encoder.layer.6.output.LayerNorm.weight torch.Size([768])\n","bert.encoder.layer.6.output.LayerNorm.bias torch.Size([768])\n","bert.encoder.layer.7.attention.self.query.weight torch.Size([768, 768])\n","bert.encoder.layer.7.attention.self.query.bias torch.Size([768])\n","bert.encoder.layer.7.attention.self.key.weight torch.Size([768, 768])\n","bert.encoder.layer.7.attention.self.key.bias torch.Size([768])\n","bert.encoder.layer.7.attention.self.value.weight torch.Size([768, 768])\n","bert.encoder.layer.7.attention.self.value.bias torch.Size([768])\n","bert.encoder.layer.7.attention.output.dense.weight torch.Size([768, 768])\n","bert.encoder.layer.7.attention.output.dense.bias torch.Size([768])\n","bert.encoder.layer.7.attention.output.LayerNorm.weight torch.Size([768])\n","bert.encoder.layer.7.attention.output.LayerNorm.bias torch.Size([768])\n","bert.encoder.layer.7.intermediate.dense.weight torch.Size([3072, 768])\n","bert.encoder.layer.7.intermediate.dense.bias torch.Size([3072])\n","bert.encoder.layer.7.output.dense.weight torch.Size([768, 3072])\n","bert.encoder.layer.7.output.dense.bias torch.Size([768])\n","bert.encoder.layer.7.output.LayerNorm.weight torch.Size([768])\n","bert.encoder.layer.7.output.LayerNorm.bias torch.Size([768])\n","bert.encoder.layer.8.attention.self.query.weight torch.Size([768, 768])\n","bert.encoder.layer.8.attention.self.query.bias torch.Size([768])\n","bert.encoder.layer.8.attention.self.key.weight torch.Size([768, 768])\n","bert.encoder.layer.8.attention.self.key.bias torch.Size([768])\n","bert.encoder.layer.8.attention.self.value.weight torch.Size([768, 768])\n","bert.encoder.layer.8.attention.self.value.bias torch.Size([768])\n","bert.encoder.layer.8.attention.output.dense.weight torch.Size([768, 768])\n","bert.encoder.layer.8.attention.output.dense.bias torch.Size([768])\n","bert.encoder.layer.8.attention.output.LayerNorm.weight torch.Size([768])\n","bert.encoder.layer.8.attention.output.LayerNorm.bias torch.Size([768])\n","bert.encoder.layer.8.intermediate.dense.weight torch.Size([3072, 768])\n","bert.encoder.layer.8.intermediate.dense.bias torch.Size([3072])\n","bert.encoder.layer.8.output.dense.weight torch.Size([768, 3072])\n","bert.encoder.layer.8.output.dense.bias torch.Size([768])\n","bert.encoder.layer.8.output.LayerNorm.weight torch.Size([768])\n","bert.encoder.layer.8.output.LayerNorm.bias torch.Size([768])\n","bert.encoder.layer.9.attention.self.query.weight torch.Size([768, 768])\n","bert.encoder.layer.9.attention.self.query.bias torch.Size([768])\n","bert.encoder.layer.9.attention.self.key.weight torch.Size([768, 768])\n","bert.encoder.layer.9.attention.self.key.bias torch.Size([768])\n","bert.encoder.layer.9.attention.self.value.weight torch.Size([768, 768])\n","bert.encoder.layer.9.attention.self.value.bias torch.Size([768])\n","bert.encoder.layer.9.attention.output.dense.weight torch.Size([768, 768])\n","bert.encoder.layer.9.attention.output.dense.bias torch.Size([768])\n","bert.encoder.layer.9.attention.output.LayerNorm.weight torch.Size([768])\n","bert.encoder.layer.9.attention.output.LayerNorm.bias torch.Size([768])\n","bert.encoder.layer.9.intermediate.dense.weight torch.Size([3072, 768])\n","bert.encoder.layer.9.intermediate.dense.bias torch.Size([3072])\n","bert.encoder.layer.9.output.dense.weight torch.Size([768, 3072])\n","bert.encoder.layer.9.output.dense.bias torch.Size([768])\n","bert.encoder.layer.9.output.LayerNorm.weight torch.Size([768])\n","bert.encoder.layer.9.output.LayerNorm.bias torch.Size([768])\n","bert.encoder.layer.10.attention.self.query.weight torch.Size([768, 768])\n","bert.encoder.layer.10.attention.self.query.bias torch.Size([768])\n","bert.encoder.layer.10.attention.self.key.weight torch.Size([768, 768])\n","bert.encoder.layer.10.attention.self.key.bias torch.Size([768])\n","bert.encoder.layer.10.attention.self.value.weight torch.Size([768, 768])\n","bert.encoder.layer.10.attention.self.value.bias torch.Size([768])\n","bert.encoder.layer.10.attention.output.dense.weight torch.Size([768, 768])\n","bert.encoder.layer.10.attention.output.dense.bias torch.Size([768])\n","bert.encoder.layer.10.attention.output.LayerNorm.weight torch.Size([768])\n","bert.encoder.layer.10.attention.output.LayerNorm.bias torch.Size([768])\n","bert.encoder.layer.10.intermediate.dense.weight torch.Size([3072, 768])\n","bert.encoder.layer.10.intermediate.dense.bias torch.Size([3072])\n","bert.encoder.layer.10.output.dense.weight torch.Size([768, 3072])\n","bert.encoder.layer.10.output.dense.bias torch.Size([768])\n","bert.encoder.layer.10.output.LayerNorm.weight torch.Size([768])\n","bert.encoder.layer.10.output.LayerNorm.bias torch.Size([768])\n","bert.encoder.layer.11.attention.self.query.weight torch.Size([768, 768])\n","bert.encoder.layer.11.attention.self.query.bias torch.Size([768])\n","bert.encoder.layer.11.attention.self.key.weight torch.Size([768, 768])\n","bert.encoder.layer.11.attention.self.key.bias torch.Size([768])\n","bert.encoder.layer.11.attention.self.value.weight torch.Size([768, 768])\n","bert.encoder.layer.11.attention.self.value.bias torch.Size([768])\n","bert.encoder.layer.11.attention.output.dense.weight torch.Size([768, 768])\n","bert.encoder.layer.11.attention.output.dense.bias torch.Size([768])\n","bert.encoder.layer.11.attention.output.LayerNorm.weight torch.Size([768])\n","bert.encoder.layer.11.attention.output.LayerNorm.bias torch.Size([768])\n","bert.encoder.layer.11.intermediate.dense.weight torch.Size([3072, 768])\n","bert.encoder.layer.11.intermediate.dense.bias torch.Size([3072])\n","bert.encoder.layer.11.output.dense.weight torch.Size([768, 3072])\n","bert.encoder.layer.11.output.dense.bias torch.Size([768])\n","bert.encoder.layer.11.output.LayerNorm.weight torch.Size([768])\n","bert.encoder.layer.11.output.LayerNorm.bias torch.Size([768])\n","cls.predictions.bias torch.Size([30522])\n","cls.predictions.transform.dense.weight torch.Size([768, 768])\n","cls.predictions.transform.dense.bias torch.Size([768])\n","cls.predictions.transform.LayerNorm.weight torch.Size([768])\n","cls.predictions.transform.LayerNorm.bias torch.Size([768])\n"]}]}]}